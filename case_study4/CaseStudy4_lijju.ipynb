{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Case Study 4 DS7333\n",
    "### Business Understanding\n",
    "<font color='blue'> The goal of this case study is to analyze various finiancial and operating parameters of companies and predict if a company will eventually file for bankruptcy. These results should inturn help investors make right choices in where then should invest. </font>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import arff\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "os.getcwd()\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression, \\\n",
    "LogisticRegressionCV\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, \\\n",
    "GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import precision_score, accuracy_score, recall_score, \\\n",
    "f1_score, roc_curve, auc\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from xgboost import plot_tree\n",
    "from sklearn import tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='blue'> Exploring the available Data <br>\n",
    "<font color='blue'> <b> We have data from 10173 companies collected over the period of 5 years. There are about 64 features describing the company and there is a target feature which tells us if the company went bankrupt or not. </b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2year.arff', '3year.arff', '5year.arff', '4year.arff', '1year.arff']"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "dir_files = [f for f in os.listdir(os.getcwd() + '/data') if os.path.isfile(join(os.getcwd() + '/data', f))]\n",
    "dir_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10173, 65)\n",
      "(10503, 65)\n",
      "(5910, 65)\n",
      "(9792, 65)\n",
      "(7027, 65)\n",
      "43405\n"
     ]
    }
   ],
   "source": [
    "data_dict = {}\n",
    "full_df = pd.DataFrame()\n",
    "\n",
    "records = 0\n",
    "\n",
    "for f in dir_files:\n",
    "    temp_data = arff.loadarff(os.getcwd() + '/data/' +f)\n",
    "    temp_df = pd.DataFrame(temp_data[0])\n",
    "    print(temp_df.shape)\n",
    "    data_dict.update({f:temp_df})\n",
    "    full_df = pd.concat([full_df, temp_df])\n",
    "    records += temp_df.shape[0]\n",
    "\n",
    "print(records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(43405, 65)"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Attr1</th>\n",
       "      <th>Attr2</th>\n",
       "      <th>Attr3</th>\n",
       "      <th>Attr4</th>\n",
       "      <th>Attr5</th>\n",
       "      <th>Attr6</th>\n",
       "      <th>Attr7</th>\n",
       "      <th>Attr8</th>\n",
       "      <th>Attr9</th>\n",
       "      <th>Attr10</th>\n",
       "      <th>...</th>\n",
       "      <th>Attr56</th>\n",
       "      <th>Attr57</th>\n",
       "      <th>Attr58</th>\n",
       "      <th>Attr59</th>\n",
       "      <th>Attr60</th>\n",
       "      <th>Attr61</th>\n",
       "      <th>Attr62</th>\n",
       "      <th>Attr63</th>\n",
       "      <th>Attr64</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.202350</td>\n",
       "      <td>0.46500</td>\n",
       "      <td>0.240380</td>\n",
       "      <td>1.5171</td>\n",
       "      <td>-14.547</td>\n",
       "      <td>0.510690</td>\n",
       "      <td>0.25366</td>\n",
       "      <td>0.91816</td>\n",
       "      <td>1.15190</td>\n",
       "      <td>0.42695</td>\n",
       "      <td>...</td>\n",
       "      <td>0.13184</td>\n",
       "      <td>0.473950</td>\n",
       "      <td>0.86816</td>\n",
       "      <td>0.00024</td>\n",
       "      <td>8.5487</td>\n",
       "      <td>5.16550</td>\n",
       "      <td>107.740</td>\n",
       "      <td>3.38790</td>\n",
       "      <td>5.3440</td>\n",
       "      <td>b'0'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.030073</td>\n",
       "      <td>0.59563</td>\n",
       "      <td>0.186680</td>\n",
       "      <td>1.3382</td>\n",
       "      <td>-37.859</td>\n",
       "      <td>-0.000319</td>\n",
       "      <td>0.04167</td>\n",
       "      <td>0.67890</td>\n",
       "      <td>0.32356</td>\n",
       "      <td>0.40437</td>\n",
       "      <td>...</td>\n",
       "      <td>0.12146</td>\n",
       "      <td>0.074369</td>\n",
       "      <td>0.87235</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.5264</td>\n",
       "      <td>0.63305</td>\n",
       "      <td>622.660</td>\n",
       "      <td>0.58619</td>\n",
       "      <td>1.2381</td>\n",
       "      <td>b'0'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.257860</td>\n",
       "      <td>0.29949</td>\n",
       "      <td>0.665190</td>\n",
       "      <td>3.2211</td>\n",
       "      <td>71.799</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.31877</td>\n",
       "      <td>2.33200</td>\n",
       "      <td>1.67620</td>\n",
       "      <td>0.69841</td>\n",
       "      <td>...</td>\n",
       "      <td>0.16499</td>\n",
       "      <td>0.369210</td>\n",
       "      <td>0.81614</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>4.3325</td>\n",
       "      <td>3.19850</td>\n",
       "      <td>65.215</td>\n",
       "      <td>5.59690</td>\n",
       "      <td>47.4660</td>\n",
       "      <td>b'0'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.227160</td>\n",
       "      <td>0.67850</td>\n",
       "      <td>0.042784</td>\n",
       "      <td>1.0828</td>\n",
       "      <td>-88.212</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.28505</td>\n",
       "      <td>0.47384</td>\n",
       "      <td>1.32410</td>\n",
       "      <td>0.32150</td>\n",
       "      <td>...</td>\n",
       "      <td>0.29358</td>\n",
       "      <td>0.706570</td>\n",
       "      <td>0.78617</td>\n",
       "      <td>0.48456</td>\n",
       "      <td>5.2309</td>\n",
       "      <td>5.06750</td>\n",
       "      <td>142.460</td>\n",
       "      <td>2.56210</td>\n",
       "      <td>3.0066</td>\n",
       "      <td>b'0'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.085443</td>\n",
       "      <td>0.38039</td>\n",
       "      <td>0.359230</td>\n",
       "      <td>1.9444</td>\n",
       "      <td>21.731</td>\n",
       "      <td>0.187900</td>\n",
       "      <td>0.10823</td>\n",
       "      <td>1.37140</td>\n",
       "      <td>1.11260</td>\n",
       "      <td>0.52167</td>\n",
       "      <td>...</td>\n",
       "      <td>0.10124</td>\n",
       "      <td>0.163790</td>\n",
       "      <td>0.89876</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>5.7035</td>\n",
       "      <td>4.00200</td>\n",
       "      <td>89.058</td>\n",
       "      <td>4.09840</td>\n",
       "      <td>5.9874</td>\n",
       "      <td>b'0'</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 65 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Attr1    Attr2     Attr3   Attr4   Attr5     Attr6    Attr7    Attr8  \\\n",
       "0  0.202350  0.46500  0.240380  1.5171 -14.547  0.510690  0.25366  0.91816   \n",
       "1  0.030073  0.59563  0.186680  1.3382 -37.859 -0.000319  0.04167  0.67890   \n",
       "2  0.257860  0.29949  0.665190  3.2211  71.799  0.000000  0.31877  2.33200   \n",
       "3  0.227160  0.67850  0.042784  1.0828 -88.212  0.000000  0.28505  0.47384   \n",
       "4  0.085443  0.38039  0.359230  1.9444  21.731  0.187900  0.10823  1.37140   \n",
       "\n",
       "     Attr9   Attr10  ...   Attr56    Attr57   Attr58   Attr59  Attr60  \\\n",
       "0  1.15190  0.42695  ...  0.13184  0.473950  0.86816  0.00024  8.5487   \n",
       "1  0.32356  0.40437  ...  0.12146  0.074369  0.87235  0.00000  1.5264   \n",
       "2  1.67620  0.69841  ...  0.16499  0.369210  0.81614  0.00000  4.3325   \n",
       "3  1.32410  0.32150  ...  0.29358  0.706570  0.78617  0.48456  5.2309   \n",
       "4  1.11260  0.52167  ...  0.10124  0.163790  0.89876  0.00000  5.7035   \n",
       "\n",
       "    Attr61   Attr62   Attr63   Attr64  class  \n",
       "0  5.16550  107.740  3.38790   5.3440   b'0'  \n",
       "1  0.63305  622.660  0.58619   1.2381   b'0'  \n",
       "2  3.19850   65.215  5.59690  47.4660   b'0'  \n",
       "3  5.06750  142.460  2.56210   3.0066   b'0'  \n",
       "4  4.00200   89.058  4.09840   5.9874   b'0'  \n",
       "\n",
       "[5 rows x 65 columns]"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'><b> As we see in the output of describe function below, each feature has different max and min ranges. \n",
    "The data will have to be standardized as before modeling </b> </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Attr1</th>\n",
       "      <th>Attr2</th>\n",
       "      <th>Attr3</th>\n",
       "      <th>Attr4</th>\n",
       "      <th>Attr5</th>\n",
       "      <th>Attr6</th>\n",
       "      <th>Attr7</th>\n",
       "      <th>Attr8</th>\n",
       "      <th>Attr9</th>\n",
       "      <th>Attr10</th>\n",
       "      <th>...</th>\n",
       "      <th>Attr55</th>\n",
       "      <th>Attr56</th>\n",
       "      <th>Attr57</th>\n",
       "      <th>Attr58</th>\n",
       "      <th>Attr59</th>\n",
       "      <th>Attr60</th>\n",
       "      <th>Attr61</th>\n",
       "      <th>Attr62</th>\n",
       "      <th>Attr63</th>\n",
       "      <th>Attr64</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>43397.000000</td>\n",
       "      <td>43397.000000</td>\n",
       "      <td>43397.000000</td>\n",
       "      <td>43271.000000</td>\n",
       "      <td>4.331600e+04</td>\n",
       "      <td>43397.000000</td>\n",
       "      <td>43397.000000</td>\n",
       "      <td>43311.000000</td>\n",
       "      <td>43396.000000</td>\n",
       "      <td>43397.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>4.340400e+04</td>\n",
       "      <td>4.327800e+04</td>\n",
       "      <td>43398.000000</td>\n",
       "      <td>4.332100e+04</td>\n",
       "      <td>43398.000000</td>\n",
       "      <td>4.125300e+04</td>\n",
       "      <td>43303.000000</td>\n",
       "      <td>4.327800e+04</td>\n",
       "      <td>43271.000000</td>\n",
       "      <td>42593.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.035160</td>\n",
       "      <td>0.590212</td>\n",
       "      <td>0.114431</td>\n",
       "      <td>6.314702</td>\n",
       "      <td>-3.853466e+02</td>\n",
       "      <td>-0.056107</td>\n",
       "      <td>0.093478</td>\n",
       "      <td>12.640779</td>\n",
       "      <td>2.652166</td>\n",
       "      <td>0.626868</td>\n",
       "      <td>...</td>\n",
       "      <td>7.672188e+03</td>\n",
       "      <td>-2.621959e+01</td>\n",
       "      <td>-0.010510</td>\n",
       "      <td>3.002644e+01</td>\n",
       "      <td>1.333288</td>\n",
       "      <td>4.480858e+02</td>\n",
       "      <td>17.033202</td>\n",
       "      <td>1.502328e+03</td>\n",
       "      <td>9.343074</td>\n",
       "      <td>72.788592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.994109</td>\n",
       "      <td>5.842748</td>\n",
       "      <td>5.439429</td>\n",
       "      <td>295.434425</td>\n",
       "      <td>6.124303e+04</td>\n",
       "      <td>7.201326</td>\n",
       "      <td>5.713075</td>\n",
       "      <td>505.894281</td>\n",
       "      <td>62.932732</td>\n",
       "      <td>14.670597</td>\n",
       "      <td>...</td>\n",
       "      <td>7.005310e+04</td>\n",
       "      <td>5.327862e+03</td>\n",
       "      <td>13.674072</td>\n",
       "      <td>5.334454e+03</td>\n",
       "      <td>122.104445</td>\n",
       "      <td>3.234560e+04</td>\n",
       "      <td>553.049406</td>\n",
       "      <td>1.392667e+05</td>\n",
       "      <td>124.177354</td>\n",
       "      <td>2369.339482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-463.890000</td>\n",
       "      <td>-430.870000</td>\n",
       "      <td>-479.960000</td>\n",
       "      <td>-0.403110</td>\n",
       "      <td>-1.190300e+07</td>\n",
       "      <td>-508.410000</td>\n",
       "      <td>-517.480000</td>\n",
       "      <td>-141.410000</td>\n",
       "      <td>-3.496000</td>\n",
       "      <td>-479.910000</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.805200e+06</td>\n",
       "      <td>-1.108300e+06</td>\n",
       "      <td>-1667.300000</td>\n",
       "      <td>-1.986900e+02</td>\n",
       "      <td>-327.970000</td>\n",
       "      <td>-1.244000e+01</td>\n",
       "      <td>-12.656000</td>\n",
       "      <td>-2.336500e+06</td>\n",
       "      <td>-1.543200</td>\n",
       "      <td>-10677.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.003429</td>\n",
       "      <td>0.268980</td>\n",
       "      <td>0.021521</td>\n",
       "      <td>1.049500</td>\n",
       "      <td>-4.908000e+01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005776</td>\n",
       "      <td>0.430275</td>\n",
       "      <td>1.018500</td>\n",
       "      <td>0.295470</td>\n",
       "      <td>...</td>\n",
       "      <td>2.755425e+01</td>\n",
       "      <td>9.348500e-03</td>\n",
       "      <td>0.014649</td>\n",
       "      <td>8.753200e-01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.545500e+00</td>\n",
       "      <td>4.510150</td>\n",
       "      <td>4.214400e+01</td>\n",
       "      <td>3.097650</td>\n",
       "      <td>2.176800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.049660</td>\n",
       "      <td>0.471900</td>\n",
       "      <td>0.196610</td>\n",
       "      <td>1.569800</td>\n",
       "      <td>-1.034500e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.059634</td>\n",
       "      <td>1.070400</td>\n",
       "      <td>1.195350</td>\n",
       "      <td>0.505970</td>\n",
       "      <td>...</td>\n",
       "      <td>1.088350e+03</td>\n",
       "      <td>5.294300e-02</td>\n",
       "      <td>0.119670</td>\n",
       "      <td>9.509600e-01</td>\n",
       "      <td>0.006366</td>\n",
       "      <td>9.791700e+00</td>\n",
       "      <td>6.636300</td>\n",
       "      <td>7.132600e+01</td>\n",
       "      <td>5.087600</td>\n",
       "      <td>4.282500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.129580</td>\n",
       "      <td>0.688320</td>\n",
       "      <td>0.403390</td>\n",
       "      <td>2.787450</td>\n",
       "      <td>5.063425e+01</td>\n",
       "      <td>0.089446</td>\n",
       "      <td>0.150880</td>\n",
       "      <td>2.615700</td>\n",
       "      <td>2.062500</td>\n",
       "      <td>0.709100</td>\n",
       "      <td>...</td>\n",
       "      <td>4.993325e+03</td>\n",
       "      <td>1.290975e-01</td>\n",
       "      <td>0.284605</td>\n",
       "      <td>9.926400e-01</td>\n",
       "      <td>0.236052</td>\n",
       "      <td>2.018100e+01</td>\n",
       "      <td>10.394500</td>\n",
       "      <td>1.172200e+02</td>\n",
       "      <td>8.598850</td>\n",
       "      <td>9.776200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>94.280000</td>\n",
       "      <td>480.960000</td>\n",
       "      <td>28.336000</td>\n",
       "      <td>53433.000000</td>\n",
       "      <td>1.250100e+06</td>\n",
       "      <td>543.250000</td>\n",
       "      <td>649.230000</td>\n",
       "      <td>53432.000000</td>\n",
       "      <td>9742.300000</td>\n",
       "      <td>1099.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>6.123700e+06</td>\n",
       "      <td>2.931500e+02</td>\n",
       "      <td>552.640000</td>\n",
       "      <td>1.108300e+06</td>\n",
       "      <td>23853.000000</td>\n",
       "      <td>4.818700e+06</td>\n",
       "      <td>108000.000000</td>\n",
       "      <td>2.501600e+07</td>\n",
       "      <td>23454.000000</td>\n",
       "      <td>294770.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Attr1         Attr2         Attr3         Attr4         Attr5  \\\n",
       "count  43397.000000  43397.000000  43397.000000  43271.000000  4.331600e+04   \n",
       "mean       0.035160      0.590212      0.114431      6.314702 -3.853466e+02   \n",
       "std        2.994109      5.842748      5.439429    295.434425  6.124303e+04   \n",
       "min     -463.890000   -430.870000   -479.960000     -0.403110 -1.190300e+07   \n",
       "25%        0.003429      0.268980      0.021521      1.049500 -4.908000e+01   \n",
       "50%        0.049660      0.471900      0.196610      1.569800 -1.034500e+00   \n",
       "75%        0.129580      0.688320      0.403390      2.787450  5.063425e+01   \n",
       "max       94.280000    480.960000     28.336000  53433.000000  1.250100e+06   \n",
       "\n",
       "              Attr6         Attr7         Attr8         Attr9        Attr10  \\\n",
       "count  43397.000000  43397.000000  43311.000000  43396.000000  43397.000000   \n",
       "mean      -0.056107      0.093478     12.640779      2.652166      0.626868   \n",
       "std        7.201326      5.713075    505.894281     62.932732     14.670597   \n",
       "min     -508.410000   -517.480000   -141.410000     -3.496000   -479.910000   \n",
       "25%        0.000000      0.005776      0.430275      1.018500      0.295470   \n",
       "50%        0.000000      0.059634      1.070400      1.195350      0.505970   \n",
       "75%        0.089446      0.150880      2.615700      2.062500      0.709100   \n",
       "max      543.250000    649.230000  53432.000000   9742.300000   1099.500000   \n",
       "\n",
       "       ...        Attr55        Attr56        Attr57        Attr58  \\\n",
       "count  ...  4.340400e+04  4.327800e+04  43398.000000  4.332100e+04   \n",
       "mean   ...  7.672188e+03 -2.621959e+01     -0.010510  3.002644e+01   \n",
       "std    ...  7.005310e+04  5.327862e+03     13.674072  5.334454e+03   \n",
       "min    ... -1.805200e+06 -1.108300e+06  -1667.300000 -1.986900e+02   \n",
       "25%    ...  2.755425e+01  9.348500e-03      0.014649  8.753200e-01   \n",
       "50%    ...  1.088350e+03  5.294300e-02      0.119670  9.509600e-01   \n",
       "75%    ...  4.993325e+03  1.290975e-01      0.284605  9.926400e-01   \n",
       "max    ...  6.123700e+06  2.931500e+02    552.640000  1.108300e+06   \n",
       "\n",
       "             Attr59        Attr60         Attr61        Attr62        Attr63  \\\n",
       "count  43398.000000  4.125300e+04   43303.000000  4.327800e+04  43271.000000   \n",
       "mean       1.333288  4.480858e+02      17.033202  1.502328e+03      9.343074   \n",
       "std      122.104445  3.234560e+04     553.049406  1.392667e+05    124.177354   \n",
       "min     -327.970000 -1.244000e+01     -12.656000 -2.336500e+06     -1.543200   \n",
       "25%        0.000000  5.545500e+00       4.510150  4.214400e+01      3.097650   \n",
       "50%        0.006366  9.791700e+00       6.636300  7.132600e+01      5.087600   \n",
       "75%        0.236052  2.018100e+01      10.394500  1.172200e+02      8.598850   \n",
       "max    23853.000000  4.818700e+06  108000.000000  2.501600e+07  23454.000000   \n",
       "\n",
       "              Attr64  \n",
       "count   42593.000000  \n",
       "mean       72.788592  \n",
       "std      2369.339482  \n",
       "min    -10677.000000  \n",
       "25%         2.176800  \n",
       "50%         4.282500  \n",
       "75%         9.776200  \n",
       "max    294770.000000  \n",
       "\n",
       "[8 rows x 64 columns]"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Attr1', 'Attr2', 'Attr3', 'Attr4', 'Attr5', 'Attr6', 'Attr7',\n",
       "       'Attr8', 'Attr9', 'Attr10', 'Attr11', 'Attr12', 'Attr13', 'Attr14',\n",
       "       'Attr15', 'Attr16', 'Attr17', 'Attr18', 'Attr19', 'Attr20',\n",
       "       'Attr21', 'Attr22', 'Attr23', 'Attr24', 'Attr25', 'Attr26',\n",
       "       'Attr27', 'Attr28', 'Attr29', 'Attr30', 'Attr31', 'Attr32',\n",
       "       'Attr33', 'Attr34', 'Attr35', 'Attr36', 'Attr37', 'Attr38',\n",
       "       'Attr39', 'Attr40', 'Attr41', 'Attr42', 'Attr43', 'Attr44',\n",
       "       'Attr45', 'Attr46', 'Attr47', 'Attr48', 'Attr49', 'Attr50',\n",
       "       'Attr51', 'Attr52', 'Attr53', 'Attr54', 'Attr55', 'Attr56',\n",
       "       'Attr57', 'Attr58', 'Attr59', 'Attr60', 'Attr61', 'Attr62',\n",
       "       'Attr63', 'Attr64', 'class'], dtype=object)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_df.columns.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> <font color='blue'> The target feature is a string which indicates 'no bankruptcy' if it is b'0' and bankruptcy if it is b'1'. Before \n",
    "modeling, we need to convert this to numerical values which is achieved below </font></b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([b'0', b'1'], dtype=object)"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_df['class'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'0'    41314\n",
       "b'1'     2091\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_df['class'].value_counts(normalize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'0'    0.951826\n",
       "b'1'    0.048174\n",
       "Name: class, dtype: float64"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_df['class'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From above, data is imbalanced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = []\n",
    "\n",
    "for index, row in full_df.iterrows():\n",
    "    class_val = row['class']\n",
    "    if class_val not in classes:\n",
    "        classes.append(class_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[b'0', b'1']"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{b'0': 0, b'1': 1}"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_dict = {}\n",
    "\n",
    "for index, i in enumerate(classes):\n",
    "    class_dict.update({i:index})\n",
    "\n",
    "class_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df['class'] = full_df['class'].map(class_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_df['class'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'><b> The view of full data frame and its feature data types is as below </b> </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 43405 entries, 0 to 7026\n",
      "Data columns (total 65 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   Attr1   43397 non-null  float64\n",
      " 1   Attr2   43397 non-null  float64\n",
      " 2   Attr3   43397 non-null  float64\n",
      " 3   Attr4   43271 non-null  float64\n",
      " 4   Attr5   43316 non-null  float64\n",
      " 5   Attr6   43397 non-null  float64\n",
      " 6   Attr7   43397 non-null  float64\n",
      " 7   Attr8   43311 non-null  float64\n",
      " 8   Attr9   43396 non-null  float64\n",
      " 9   Attr10  43397 non-null  float64\n",
      " 10  Attr11  43361 non-null  float64\n",
      " 11  Attr12  43271 non-null  float64\n",
      " 12  Attr13  43278 non-null  float64\n",
      " 13  Attr14  43397 non-null  float64\n",
      " 14  Attr15  43369 non-null  float64\n",
      " 15  Attr16  43310 non-null  float64\n",
      " 16  Attr17  43311 non-null  float64\n",
      " 17  Attr18  43397 non-null  float64\n",
      " 18  Attr19  43277 non-null  float64\n",
      " 19  Attr20  43278 non-null  float64\n",
      " 20  Attr21  37551 non-null  float64\n",
      " 21  Attr22  43397 non-null  float64\n",
      " 22  Attr23  43278 non-null  float64\n",
      " 23  Attr24  42483 non-null  float64\n",
      " 24  Attr25  43397 non-null  float64\n",
      " 25  Attr26  43310 non-null  float64\n",
      " 26  Attr27  40641 non-null  float64\n",
      " 27  Attr28  42593 non-null  float64\n",
      " 28  Attr29  43397 non-null  float64\n",
      " 29  Attr30  43278 non-null  float64\n",
      " 30  Attr31  43278 non-null  float64\n",
      " 31  Attr32  43037 non-null  float64\n",
      " 32  Attr33  43271 non-null  float64\n",
      " 33  Attr34  43311 non-null  float64\n",
      " 34  Attr35  43397 non-null  float64\n",
      " 35  Attr36  43397 non-null  float64\n",
      " 36  Attr37  24421 non-null  float64\n",
      " 37  Attr38  43397 non-null  float64\n",
      " 38  Attr39  43278 non-null  float64\n",
      " 39  Attr40  43271 non-null  float64\n",
      " 40  Attr41  42651 non-null  float64\n",
      " 41  Attr42  43278 non-null  float64\n",
      " 42  Attr43  43278 non-null  float64\n",
      " 43  Attr44  43278 non-null  float64\n",
      " 44  Attr45  41258 non-null  float64\n",
      " 45  Attr46  43270 non-null  float64\n",
      " 46  Attr47  43108 non-null  float64\n",
      " 47  Attr48  43396 non-null  float64\n",
      " 48  Attr49  43278 non-null  float64\n",
      " 49  Attr50  43311 non-null  float64\n",
      " 50  Attr51  43397 non-null  float64\n",
      " 51  Attr52  43104 non-null  float64\n",
      " 52  Attr53  42593 non-null  float64\n",
      " 53  Attr54  42593 non-null  float64\n",
      " 54  Attr55  43404 non-null  float64\n",
      " 55  Attr56  43278 non-null  float64\n",
      " 56  Attr57  43398 non-null  float64\n",
      " 57  Attr58  43321 non-null  float64\n",
      " 58  Attr59  43398 non-null  float64\n",
      " 59  Attr60  41253 non-null  float64\n",
      " 60  Attr61  43303 non-null  float64\n",
      " 61  Attr62  43278 non-null  float64\n",
      " 62  Attr63  43271 non-null  float64\n",
      " 63  Attr64  42593 non-null  float64\n",
      " 64  class   43405 non-null  int64  \n",
      "dtypes: float64(64), int64(1)\n",
      "memory usage: 21.9 MB\n"
     ]
    }
   ],
   "source": [
    "full_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Attr1</th>\n",
       "      <th>Attr2</th>\n",
       "      <th>Attr3</th>\n",
       "      <th>Attr4</th>\n",
       "      <th>Attr5</th>\n",
       "      <th>Attr6</th>\n",
       "      <th>Attr7</th>\n",
       "      <th>Attr8</th>\n",
       "      <th>Attr9</th>\n",
       "      <th>Attr10</th>\n",
       "      <th>...</th>\n",
       "      <th>Attr56</th>\n",
       "      <th>Attr57</th>\n",
       "      <th>Attr58</th>\n",
       "      <th>Attr59</th>\n",
       "      <th>Attr60</th>\n",
       "      <th>Attr61</th>\n",
       "      <th>Attr62</th>\n",
       "      <th>Attr63</th>\n",
       "      <th>Attr64</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.202350</td>\n",
       "      <td>0.46500</td>\n",
       "      <td>0.240380</td>\n",
       "      <td>1.5171</td>\n",
       "      <td>-14.547</td>\n",
       "      <td>0.510690</td>\n",
       "      <td>0.25366</td>\n",
       "      <td>0.91816</td>\n",
       "      <td>1.15190</td>\n",
       "      <td>0.42695</td>\n",
       "      <td>...</td>\n",
       "      <td>0.13184</td>\n",
       "      <td>0.473950</td>\n",
       "      <td>0.86816</td>\n",
       "      <td>0.00024</td>\n",
       "      <td>8.5487</td>\n",
       "      <td>5.16550</td>\n",
       "      <td>107.740</td>\n",
       "      <td>3.38790</td>\n",
       "      <td>5.3440</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.030073</td>\n",
       "      <td>0.59563</td>\n",
       "      <td>0.186680</td>\n",
       "      <td>1.3382</td>\n",
       "      <td>-37.859</td>\n",
       "      <td>-0.000319</td>\n",
       "      <td>0.04167</td>\n",
       "      <td>0.67890</td>\n",
       "      <td>0.32356</td>\n",
       "      <td>0.40437</td>\n",
       "      <td>...</td>\n",
       "      <td>0.12146</td>\n",
       "      <td>0.074369</td>\n",
       "      <td>0.87235</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.5264</td>\n",
       "      <td>0.63305</td>\n",
       "      <td>622.660</td>\n",
       "      <td>0.58619</td>\n",
       "      <td>1.2381</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.257860</td>\n",
       "      <td>0.29949</td>\n",
       "      <td>0.665190</td>\n",
       "      <td>3.2211</td>\n",
       "      <td>71.799</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.31877</td>\n",
       "      <td>2.33200</td>\n",
       "      <td>1.67620</td>\n",
       "      <td>0.69841</td>\n",
       "      <td>...</td>\n",
       "      <td>0.16499</td>\n",
       "      <td>0.369210</td>\n",
       "      <td>0.81614</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>4.3325</td>\n",
       "      <td>3.19850</td>\n",
       "      <td>65.215</td>\n",
       "      <td>5.59690</td>\n",
       "      <td>47.4660</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.227160</td>\n",
       "      <td>0.67850</td>\n",
       "      <td>0.042784</td>\n",
       "      <td>1.0828</td>\n",
       "      <td>-88.212</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.28505</td>\n",
       "      <td>0.47384</td>\n",
       "      <td>1.32410</td>\n",
       "      <td>0.32150</td>\n",
       "      <td>...</td>\n",
       "      <td>0.29358</td>\n",
       "      <td>0.706570</td>\n",
       "      <td>0.78617</td>\n",
       "      <td>0.48456</td>\n",
       "      <td>5.2309</td>\n",
       "      <td>5.06750</td>\n",
       "      <td>142.460</td>\n",
       "      <td>2.56210</td>\n",
       "      <td>3.0066</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.085443</td>\n",
       "      <td>0.38039</td>\n",
       "      <td>0.359230</td>\n",
       "      <td>1.9444</td>\n",
       "      <td>21.731</td>\n",
       "      <td>0.187900</td>\n",
       "      <td>0.10823</td>\n",
       "      <td>1.37140</td>\n",
       "      <td>1.11260</td>\n",
       "      <td>0.52167</td>\n",
       "      <td>...</td>\n",
       "      <td>0.10124</td>\n",
       "      <td>0.163790</td>\n",
       "      <td>0.89876</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>5.7035</td>\n",
       "      <td>4.00200</td>\n",
       "      <td>89.058</td>\n",
       "      <td>4.09840</td>\n",
       "      <td>5.9874</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 65 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Attr1    Attr2     Attr3   Attr4   Attr5     Attr6    Attr7    Attr8  \\\n",
       "0  0.202350  0.46500  0.240380  1.5171 -14.547  0.510690  0.25366  0.91816   \n",
       "1  0.030073  0.59563  0.186680  1.3382 -37.859 -0.000319  0.04167  0.67890   \n",
       "2  0.257860  0.29949  0.665190  3.2211  71.799  0.000000  0.31877  2.33200   \n",
       "3  0.227160  0.67850  0.042784  1.0828 -88.212  0.000000  0.28505  0.47384   \n",
       "4  0.085443  0.38039  0.359230  1.9444  21.731  0.187900  0.10823  1.37140   \n",
       "\n",
       "     Attr9   Attr10  ...   Attr56    Attr57   Attr58   Attr59  Attr60  \\\n",
       "0  1.15190  0.42695  ...  0.13184  0.473950  0.86816  0.00024  8.5487   \n",
       "1  0.32356  0.40437  ...  0.12146  0.074369  0.87235  0.00000  1.5264   \n",
       "2  1.67620  0.69841  ...  0.16499  0.369210  0.81614  0.00000  4.3325   \n",
       "3  1.32410  0.32150  ...  0.29358  0.706570  0.78617  0.48456  5.2309   \n",
       "4  1.11260  0.52167  ...  0.10124  0.163790  0.89876  0.00000  5.7035   \n",
       "\n",
       "    Attr61   Attr62   Attr63   Attr64  class  \n",
       "0  5.16550  107.740  3.38790   5.3440      0  \n",
       "1  0.63305  622.660  0.58619   1.2381      0  \n",
       "2  3.19850   65.215  5.59690  47.4660      0  \n",
       "3  5.06750  142.460  2.56210   3.0066      0  \n",
       "4  4.00200   89.058  4.09840   5.9874      0  \n",
       "\n",
       "[5 rows x 65 columns]"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Data Evaluation\n",
    "<font color='blue'>\n",
    "1. The dataset consists of 64 different attributes for over 10,000 different companies over a period of 5 years. <br>\n",
    "2. We can see from the class variable only around 5% of the companies ended up filing bankruptcy.so, the dataset is imbalanced. Accuracy would not be the right metric since we have imbalanced data.<br>\n",
    "3. In this scenario based on our problem that we are solving, the cost of False Negative would be high and Recall would be right metric to evaluate models. F-score which gives a balance between precision and recall can also be used as other metric. \n",
    "   </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = full_df.loc[:, full_df.columns != 'class'].values\n",
    "y = full_df['class'].values\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.33, random_state = 42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'> Use 33% of data for test. <br>\n",
    "    Substitue missing values in all features by their respective means.\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "imp_mean = SimpleImputer(missing_values = np.nan, strategy = 'mean')\n",
    "imp_mean.fit(X_train)\n",
    "\n",
    "X_train = imp_mean.transform(X_train)\n",
    "X_test = imp_mean.transform(X_test)\n",
    "cols = full_df.columns.values.tolist()\n",
    "cols.remove('class')\n",
    "X_train = pd.DataFrame(X_train, columns=cols)\n",
    "X_test = pd.DataFrame(X_test, columns=cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest Model1 with default parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': True,\n",
       " 'ccp_alpha': 0.0,\n",
       " 'class_weight': None,\n",
       " 'criterion': 'gini',\n",
       " 'max_depth': None,\n",
       " 'max_features': 'auto',\n",
       " 'max_leaf_nodes': None,\n",
       " 'max_samples': None,\n",
       " 'min_impurity_decrease': 0.0,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'min_weight_fraction_leaf': 0.0,\n",
       " 'n_estimators': 100,\n",
       " 'n_jobs': None,\n",
       " 'oob_score': False,\n",
       " 'random_state': 0,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_clf1 = RandomForestClassifier(random_state = 0)\n",
    "rf_clf1.fit(X_train, y_train)\n",
    "\n",
    "rf_clf1.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix \n",
      " [[27668     0]\n",
      " [    1  1412]]\n",
      "\n",
      " Classification Report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0   0.999964  1.000000  0.999982     27668\n",
      "           1   1.000000  0.999292  0.999646      1413\n",
      "\n",
      "    accuracy                       0.999966     29081\n",
      "   macro avg   0.999982  0.999646  0.999814     29081\n",
      "weighted avg   0.999966  0.999966  0.999966     29081\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_hat_rf_train1 = rf_clf1.predict(X_train)\n",
    "print(\"Confusion Matrix \\n\",confusion_matrix(y_train, y_hat_rf_train1))\n",
    "print(\"\\n Classification Report \\n\",classification_report(y_train, y_hat_rf_train1, digits=6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix \n",
      " [[13608    38]\n",
      " [  460   218]]\n",
      "\n",
      " Classification Report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0   0.967302  0.997215  0.982031     13646\n",
      "           1   0.851562  0.321534  0.466809       678\n",
      "\n",
      "    accuracy                       0.965233     14324\n",
      "   macro avg   0.909432  0.659375  0.724420     14324\n",
      "weighted avg   0.961823  0.965233  0.957644     14324\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_hat_rf_test1 = rf_clf1.predict(X_test)\n",
    "print(\"Confusion Matrix \\n\",confusion_matrix(y_test, y_hat_rf_test1))\n",
    "print(\"\\n Classification Report \\n\",classification_report(y_test, y_hat_rf_test1, digits=6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "feature_importances = rf_clf1.feature_importances_\n",
    "sorted_indices = np.argsort(feature_importances)[::-1]\n",
    "plt.figure(figsize=(20,4))\n",
    "plt.title('Feature Importance')\n",
    "plt.bar(range(X_train.shape[1]), feature_importances[sorted_indices], align='center')\n",
    "plt.xticks(range(X_train.shape[1]), X_train.columns[sorted_indices], rotation=90)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'> The above bar chart shows feature importance as predicted by Random forest classifier. \n",
    "Attribute 'Attr27' is the most important one </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Top important features based on threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SelectFromModel(estimator=RandomForestClassifier(random_state=0),\n",
       "                threshold=0.02)"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sfm = SelectFromModel(rf_clf1, threshold=0.02)\n",
    "\n",
    "# Train the selector\n",
    "sfm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attr6\n",
      "Attr9\n",
      "Attr24\n",
      "Attr27\n",
      "Attr29\n",
      "Attr34\n",
      "Attr35\n",
      "Attr46\n",
      "Attr55\n",
      "Attr56\n",
      "Attr58\n"
     ]
    }
   ],
   "source": [
    "for feature_list_index in sfm.get_support(indices=True):\n",
    "    print(cols[feature_list_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_features = ['Attr6','Attr9','Attr24','Attr27','Attr29','Attr34','Attr35','Attr46','Attr55','Attr56']\n",
    "X_train_imp = X_train[imp_features]\n",
    "X_test_imp = X_test[imp_features]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest Model2 with parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix \n",
      " [[27668     0]\n",
      " [ 1111   302]]\n",
      "\n",
      " Classification Report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0   0.961395  1.000000  0.980318     27668\n",
      "           1   1.000000  0.213730  0.352187      1413\n",
      "\n",
      "    accuracy                       0.961796     29081\n",
      "   macro avg   0.980698  0.606865  0.666252     29081\n",
      "weighted avg   0.963271  0.961796  0.949798     29081\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf_clf2 = RandomForestClassifier(n_estimators = 50, max_depth = 10, min_samples_split = 100, random_state = 2)\n",
    "rf_clf2.fit(X_train, y_train)\n",
    "y_hat_rf_train2 = rf_clf2.predict(X_train)\n",
    "print(\"Confusion Matrix \\n\",confusion_matrix(y_train, y_hat_rf_train2))\n",
    "print(\"\\n Classification Report \\n\",classification_report(y_train, y_hat_rf_train2, digits=6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix \n",
      " [[13646     0]\n",
      " [  577   101]]\n",
      "\n",
      " Classification Report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0   0.959432  1.000000  0.979296     13646\n",
      "           1   1.000000  0.148968  0.259307       678\n",
      "\n",
      "    accuracy                       0.959718     14324\n",
      "   macro avg   0.979716  0.574484  0.619301     14324\n",
      "weighted avg   0.961352  0.959718  0.945217     14324\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_hat_rf_test2 = rf_clf2.predict(X_test)\n",
    "print(\"Confusion Matrix \\n\",confusion_matrix(y_test, y_hat_rf_test2))\n",
    "print(\"\\n Classification Report \\n\",classification_report(y_test, y_hat_rf_test2, digits=6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest Model3 with GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 48 candidates, totalling 96 fits\n",
      "CPU times: user 13min 22s, sys: 5.14 s, total: 13min 28s\n",
      "Wall time: 13min 32s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=2, estimator=RandomForestClassifier(random_state=42),\n",
       "             param_grid={'criterion': ['gini', 'entropy'],\n",
       "                         'max_depth': [10, 15, 20],\n",
       "                         'max_features': ['auto', 'sqrt'],\n",
       "                         'n_estimators': [25, 50, 100, 200]},\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "rf_clf3 = RandomForestClassifier(random_state=42)\n",
    "param_grid = { \n",
    "    'n_estimators': [25,50,100,200],\n",
    "    'max_features': ['auto', 'sqrt'],\n",
    "    'max_depth' : [10,15,20],\n",
    "    'criterion' :['gini', 'entropy']\n",
    "}\n",
    "CV_rfc = GridSearchCV(estimator=rf_clf3, param_grid=param_grid, cv= 2,verbose=1)\n",
    "CV_rfc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'criterion': 'gini',\n",
       " 'max_depth': 15,\n",
       " 'max_features': 'auto',\n",
       " 'n_estimators': 50}"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CV_rfc.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest Model4 with best parameters from GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix \n",
      " [[27668     0]\n",
      " [  403  1010]]\n",
      "\n",
      " Classification Report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0   0.985644  1.000000  0.992770     27668\n",
      "           1   1.000000  0.714791  0.833677      1413\n",
      "\n",
      "    accuracy                       0.986142     29081\n",
      "   macro avg   0.992822  0.857396  0.913224     29081\n",
      "weighted avg   0.986341  0.986142  0.985040     29081\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf_clf4=RandomForestClassifier(random_state=42, max_features='auto', n_estimators= 50, max_depth=15, criterion='gini')\n",
    "rf_clf4.fit(X_train, y_train)\n",
    "y_hat_rf_train4 = rf_clf4.predict(X_train)\n",
    "print(\"Confusion Matrix \\n\",confusion_matrix(y_train, y_hat_rf_train4))\n",
    "print(\"\\n Classification Report \\n\",classification_report(y_train, y_hat_rf_train4, digits=6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix \n",
      " [[13632    14]\n",
      " [  472   206]]\n",
      "\n",
      " Classification Report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0   0.966534  0.998974  0.982486     13646\n",
      "           1   0.936364  0.303835  0.458797       678\n",
      "\n",
      "    accuracy                       0.966071     14324\n",
      "   macro avg   0.951449  0.651404  0.720642     14324\n",
      "weighted avg   0.965106  0.966071  0.957699     14324\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_hat_rf_test4 = rf_clf4.predict(X_test)\n",
    "print(\"Confusion Matrix \\n\",confusion_matrix(y_test, y_hat_rf_test4))\n",
    "print(\"\\n Classification Report \\n\",classification_report(y_test, y_hat_rf_test4, digits=6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest Model5 with important features & GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 48 candidates, totalling 96 fits\n",
      "CPU times: user 4min 56s, sys: 1.51 s, total: 4min 58s\n",
      "Wall time: 4min 59s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'criterion': 'entropy',\n",
       " 'max_depth': 10,\n",
       " 'max_features': 'auto',\n",
       " 'n_estimators': 50}"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "rf_clf5 = RandomForestClassifier(random_state=42)\n",
    "param_grid = { \n",
    "    'n_estimators': [25,50,100,200],\n",
    "    'max_features': ['auto', 'sqrt'],\n",
    "    'max_depth' : [10,15,20],\n",
    "    'criterion' :['gini', 'entropy']\n",
    "}\n",
    "CV_rfc = GridSearchCV(estimator=rf_clf5, param_grid=param_grid, cv= 2,verbose=1)\n",
    "CV_rfc.fit(X_train_imp, y_train)\n",
    "CV_rfc.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest Model6 with important features, GridSearchCV and best parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix \n",
      " [[27668     0]\n",
      " [  844   569]]\n",
      "\n",
      " Classification Report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0   0.970398  1.000000  0.984977     27668\n",
      "           1   1.000000  0.402689  0.574168      1413\n",
      "\n",
      "    accuracy                       0.970978     29081\n",
      "   macro avg   0.985199  0.701345  0.779572     29081\n",
      "weighted avg   0.971837  0.970978  0.965016     29081\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf_clf6=RandomForestClassifier(random_state=42, max_features='auto', n_estimators= 50, max_depth=10, criterion='entropy')\n",
    "rf_clf6.fit(X_train_imp, y_train)\n",
    "y_hat_rf_train6 = rf_clf6.predict(X_train_imp)\n",
    "print(\"Confusion Matrix \\n\",confusion_matrix(y_train, y_hat_rf_train6))\n",
    "print(\"\\n Classification Report \\n\",classification_report(y_train, y_hat_rf_train6, digits=6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix \n",
      " [[13640     6]\n",
      " [  459   219]]\n",
      "\n",
      " Classification Report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0   0.967444  0.999560  0.983240     13646\n",
      "           1   0.973333  0.323009  0.485050       678\n",
      "\n",
      "    accuracy                       0.967537     14324\n",
      "   macro avg   0.970389  0.661285  0.734145     14324\n",
      "weighted avg   0.967723  0.967537  0.959659     14324\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_hat_rf_test6 = rf_clf6.predict(X_test_imp)\n",
    "print(\"Confusion Matrix \\n\",confusion_matrix(y_test, y_hat_rf_test6))\n",
    "print(\"\\n Classification Report \\n\",classification_report(y_test, y_hat_rf_test6, digits=6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest Model Performances\n",
    "\n",
    "| Sno | Model                                                                     | Train/Test | Accuracy | Precision | Recall | F-Score |\n",
    "|-----|---------------------------------------------------------------------------|------------|----------|-----------|--------|---------|\n",
    "| 1   | Random Forest Default Parameters                                          | Train      | 0.99     | 1         | 0.99   | 0.99    |\n",
    "|     |                                                                           | Test       | 0.96     | 0.85      | 0.32   | 0.46    |\n",
    "| 2   | Random Forest with Parameters                                             | Train      | 0.96     | 1         | 0.21   | 0.35    |\n",
    "|     |                                                                           | Test       | 0.95     | 1         | 0.14   | 0.25    |\n",
    "| 3   | Random Forest with best parameters  from GridSearchCV                     | Train      | 0.98     | 1         | 0.71   | 0.83    |\n",
    "|     |                                                                           | Test       | 0.96     | 0.93      | 0.30   | 0.45    |\n",
    "| 4   | Random Forest with Important features & best parameters from GridSearchCV | Train      | 0.97     | 1         | 0.40   | 0.57    |\n",
    "|     |                                                                           | Test       | 0.96     | 0.97      | 0.32   | 0.48    |\n",
    "\n",
    "1. We have built 4-6 models on Random forest and also performed hypertuning with GridSearchCV.\n",
    "2. Below are the top 10 attributes based on the Random Forest feature importance and threshold.\n",
    "    * Attr27 - profit on operating activities / financial expenses \n",
    "    * Attr34 - operating expenses / total liabilities\n",
    "    * Attr46 - current assets - inventory) / short-term liabilities\n",
    "    * Attr58 - total costs /total sales\n",
    "    * Attr56 - (sales - cost of products sold) / sales\n",
    "    * Attr24 - gross profit (in 3 years) / total assets\n",
    "    * Attr29 - logarithm of total assets\n",
    "    * Attr9  - sales / total assets\n",
    "    * Attr6  - retained earnings / total assets\n",
    "    * Attr55 - working capital\n",
    "    * Attr35 - profit on sales / total assets\n",
    "3. Based on recall and f-score the model4 in the above table with important features and best parameters from gridsearchcv is best model. This model also generalizes well on the test dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XGBoost Model1 with defaults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix \n",
      " [[27654    14]\n",
      " [  772   641]]\n",
      "\n",
      " Classification Report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0   0.972842  0.999494  0.985988     27668\n",
      "           1   0.978626  0.453645  0.619923      1413\n",
      "\n",
      "    accuracy                       0.972972     29081\n",
      "   macro avg   0.975734  0.726569  0.802955     29081\n",
      "weighted avg   0.973123  0.972972  0.968201     29081\n",
      "\n"
     ]
    }
   ],
   "source": [
    "xgb_clf1 = GradientBoostingClassifier(random_state=0).fit(X_train, y_train)\n",
    "y_hat_xgb_train1 = xgb_clf1.predict(X_train)\n",
    "print(\"Confusion Matrix \\n\",confusion_matrix(y_train, y_hat_xgb_train1))\n",
    "print(\"\\n Classification Report \\n\",classification_report(y_train, y_hat_xgb_train1, digits=6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix \n",
      " [[13623    23]\n",
      " [  413   265]]\n",
      "\n",
      " Classification Report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0   0.970576  0.998315  0.984250     13646\n",
      "           1   0.920139  0.390855  0.548654       678\n",
      "\n",
      "    accuracy                       0.969562     14324\n",
      "   macro avg   0.945357  0.694585  0.766452     14324\n",
      "weighted avg   0.968188  0.969562  0.963632     14324\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_hat_xgb_test1 = xgb_clf1.predict(X_test)\n",
    "print(\"Confusion Matrix \\n\",confusion_matrix(y_test, y_hat_xgb_test1))\n",
    "print(\"\\n Classification Report \\n\",classification_report(y_test, y_hat_xgb_test1, digits=6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XGBoost Model2 with hyperparmeters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix \n",
      " [[27613    55]\n",
      " [  864   549]]\n",
      "\n",
      " Classification Report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0   0.969660  0.998012  0.983632     27668\n",
      "           1   0.908940  0.388535  0.544373      1413\n",
      "\n",
      "    accuracy                       0.968399     29081\n",
      "   macro avg   0.939300  0.693274  0.764002     29081\n",
      "weighted avg   0.966709  0.968399  0.962289     29081\n",
      "\n"
     ]
    }
   ],
   "source": [
    "xgb_clf2 = GradientBoostingClassifier(n_estimators=20, learning_rate=0.5, max_depth=2, random_state=0).fit(X_train, y_train)\n",
    "y_hat_xgb_train2 = xgb_clf2.predict(X_train)\n",
    "print(\"Confusion Matrix \\n\",confusion_matrix(y_train, y_hat_xgb_train2))\n",
    "print(\"\\n Classification Report \\n\",classification_report(y_train, y_hat_xgb_train2, digits=6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix \n",
      " [[13600    46]\n",
      " [  452   226]]\n",
      "\n",
      " Classification Report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0   0.967834  0.996629  0.982020     13646\n",
      "           1   0.830882  0.333333  0.475789       678\n",
      "\n",
      "    accuracy                       0.965233     14324\n",
      "   macro avg   0.899358  0.664981  0.728905     14324\n",
      "weighted avg   0.961351  0.965233  0.958059     14324\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_hat_xgb_test2 = xgb_clf2.predict(X_test)\n",
    "print(\"Confusion Matrix \\n\",confusion_matrix(y_test, y_hat_xgb_test2))\n",
    "print(\"\\n Classification Report \\n\",classification_report(y_test, y_hat_xgb_test2, digits=6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XGBoost Model3 with Important features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix \n",
      " [[27601    67]\n",
      " [  947   466]]\n",
      "\n",
      " Classification Report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0   0.966828  0.997578  0.981962     27668\n",
      "           1   0.874296  0.329795  0.478931      1413\n",
      "\n",
      "    accuracy                       0.965132     29081\n",
      "   macro avg   0.920562  0.663687  0.730447     29081\n",
      "weighted avg   0.962332  0.965132  0.957521     29081\n",
      "\n"
     ]
    }
   ],
   "source": [
    "xgb_clf3 = GradientBoostingClassifier(n_estimators=20, learning_rate=0.5, max_depth=2, random_state=0).fit(X_train_imp, y_train)\n",
    "y_hat_xgb_train3 = xgb_clf3.predict(X_train_imp)\n",
    "print(\"Confusion Matrix \\n\",confusion_matrix(y_train, y_hat_xgb_train3))\n",
    "print(\"\\n Classification Report \\n\",classification_report(y_train, y_hat_xgb_train3, digits=6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix \n",
      " [[13599    47]\n",
      " [  478   200]]\n",
      "\n",
      " Classification Report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0   0.966044  0.996556  0.981063     13646\n",
      "           1   0.809717  0.294985  0.432432       678\n",
      "\n",
      "    accuracy                       0.963348     14324\n",
      "   macro avg   0.887880  0.645771  0.706748     14324\n",
      "weighted avg   0.958644  0.963348  0.955094     14324\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_hat_xgb_test3 = xgb_clf3.predict(X_test_imp)\n",
    "print(\"Confusion Matrix \\n\",confusion_matrix(y_test, y_hat_xgb_test3))\n",
    "print(\"\\n Classification Report \\n\",classification_report(y_test, y_hat_xgb_test3, digits=6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XGBoost Model4 with Important features & GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.7,\n",
       " 'max_depth': 8,\n",
       " 'min_samples_leaf': 0.1,\n",
       " 'n_estimators': 30}"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters = {\n",
    "    \"learning_rate\": [0.2,0.5,0.7],\n",
    "    \"min_samples_leaf\": [0.1, 0.5],\n",
    "    \"max_depth\":[3,8],\n",
    "    \"n_estimators\":[10,30]\n",
    "    }\n",
    "\n",
    "xgb_clf4 = GridSearchCV(GradientBoostingClassifier(), parameters, cv=2, n_jobs=-1)\n",
    "xgb_clf4.fit(X_train_imp, y_train)\n",
    "xgb_clf4.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XGBoost Model4 with Important features & GridSearchCV & Best Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix \n",
      " [[27611    57]\n",
      " [  916   497]]\n",
      "\n",
      " Classification Report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0   0.967890  0.997940  0.982685     27668\n",
      "           1   0.897112  0.351734  0.505338      1413\n",
      "\n",
      "    accuracy                       0.966542     29081\n",
      "   macro avg   0.932501  0.674837  0.744012     29081\n",
      "weighted avg   0.964451  0.966542  0.959492     29081\n",
      "\n"
     ]
    }
   ],
   "source": [
    "xgb_clf5 = GradientBoostingClassifier(n_estimators=30, min_samples_leaf=0.1, learning_rate=0.7, max_depth=8, random_state=0).fit(X_train_imp, y_train)\n",
    "y_hat_xgb_train5 = xgb_clf5.predict(X_train_imp)\n",
    "print(\"Confusion Matrix \\n\",confusion_matrix(y_train, y_hat_xgb_train5))\n",
    "print(\"\\n Classification Report \\n\",classification_report(y_train, y_hat_xgb_train5, digits=6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix \n",
      " [[13617    29]\n",
      " [  437   241]]\n",
      "\n",
      " Classification Report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0   0.968906  0.997875  0.983177     13646\n",
      "           1   0.892593  0.355457  0.508439       678\n",
      "\n",
      "    accuracy                       0.967467     14324\n",
      "   macro avg   0.930749  0.676666  0.745808     14324\n",
      "weighted avg   0.965294  0.967467  0.960706     14324\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_hat_xgb_test5 = xgb_clf5.predict(X_test_imp)\n",
    "print(\"Confusion Matrix \\n\",confusion_matrix(y_test, y_hat_xgb_test5))\n",
    "print(\"\\n Classification Report \\n\",classification_report(y_test, y_hat_xgb_test5, digits=6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XGBoost Model Performances\n",
    "\n",
    "| Sno | Model                                                                     | Train/Test | Accuracy | Precision | Recall | F-Score |\n",
    "|-----|---------------------------------------------------------------------------|------------|----------|-----------|--------|---------|\n",
    "| 1   | XGBoost Model Default Parameters                                          | Train      | 0.97     | 0.97      | 0.45   | 0.61    |\n",
    "|     |                                                                           | Test       | 0.96     | 0.92      | 0.39   | 0.54    |\n",
    "| 2   | XGBoost Model with Parameters                                             | Train      | 0.96     | 0.90      | 0.38   | 0.54    |\n",
    "|     |                                                                           | Test       | 0.96     | 0.83      | 0.33   | 0.47    |\n",
    "| 3   | XGBoost Model with Important features & best parameters from GridSearchCV | Train      | 0.96     | 0.89      | 0.35   | 0.50    |\n",
    "|     |                                                                           | Test       | 0.96     | 0.89      | 0.35   | 0.50    |      \n",
    "\n",
    "1. We have built 3-5 models based on XGBoost and also performed hypertuning with GridSearchCV.\n",
    "2. From the above, XGBoost Model3 with Important features and hyperparmeters from GridSearhcv has best recall and the model generalizes with the test data as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize Boosting Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Couldnt get the Visualization using the XGBoost, the kernel is crashing.\n",
    "# model = XGBClassifier()\n",
    "# model.fit(X_train_imp, y_train)\n",
    "# plot_tree(model)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "clf = DecisionTreeClassifier(max_depth = 3,random_state = 0)\n",
    "clf.fit(X_train_imp, y_train)\n",
    "clf.predict(X_test_imp)\n",
    "tree.plot_tree(clf);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='darkgreen'> <b> As seen above, the XGBoost model provides the best recall value . The suggestion is to deploy the XGBoost model to predict the bankruptcy of companies. There can be false positives produced by the model , so a second level of analysis may be required by domain experts to rule out the false positive cases. The investors portfolio health will be protected against bankruptcies by this model  </b> </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:anaconda3]",
   "language": "python",
   "name": "conda-env-anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
